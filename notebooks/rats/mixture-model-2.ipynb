{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "import mat73\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import pandas as pd\n",
    "\n",
    "import numpyro\n",
    "import numpyro.distributions as dist\n",
    "from numpyro.infer import MCMC, NUTS\n",
    "from numpyro.diagnostics import hpdi\n",
    "\n",
    "from hb_mep.config import HBMepConfig\n",
    "from hb_mep.data_access import DataClass\n",
    "from hb_mep.models.baseline import Baseline\n",
    "from hb_mep.models.utils import Site as site\n",
    "from hb_mep.utils import plot, timing\n",
    "from hb_mep.utils.constants import (\n",
    "    INTENSITY,\n",
    "    RESPONSE,\n",
    "    PARTICIPANT,\n",
    "    FEATURES\n",
    ")\n",
    "\n",
    "numpyro.set_platform(\"cpu\")\n",
    "numpyro.set_host_device_count(12)\n",
    "numpyro.enable_x64()\n",
    "\n",
    "PARENT_PATH = Path(os.getcwd()).parent.parent.absolute()\n",
    "FORMAT = \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n",
    "logging.basicConfig(format=FORMAT, level=logging.INFO)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = HBMepConfig()\n",
    "config.CURRENT_PATH = PARENT_PATH\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data and preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-26 15:10:14,597 - hb_mep.data_access.core - INFO - Processing data ...\n",
      "2023-05-26 15:10:14,604 - hb_mep.utils.utils - INFO - func:preprocess took: 0.01 sec\n",
      "2023-05-26 15:10:14,604 - hb_mep.utils.utils - INFO - func:build took: 0.01 sec\n"
     ]
    }
   ],
   "source": [
    "data = DataClass(config)\n",
    "\n",
    "a, b = 2, 3\n",
    "df = None\n",
    "\n",
    "for i in range(a, b):\n",
    "    participant = f\"amap{i:02}\"\n",
    "    PREFIX = f\"rats_data/{participant}/*\"\n",
    "\n",
    "    fpath = glob.glob(os.path.join(data.data_path, f\"{PREFIX}/*auc_table.csv\"))[0]\n",
    "    temp_df = pd.read_csv(fpath)\n",
    "\n",
    "    fpath = glob.glob(os.path.join(data.data_path, f\"{PREFIX}/*ep_matrix.mat\"))[0]\n",
    "    data_dict = mat73.loadmat(fpath)\n",
    "    temp_mat = data_dict[\"ep_sliced\"]\n",
    "\n",
    "    if df is None:\n",
    "        time = data_dict[\"t_sliced\"]\n",
    "    else:\n",
    "        assert((data_dict[\"t_sliced\"] == time).all())\n",
    "\n",
    "    temp_df[\"participant\"] = participant\n",
    "    temp_df[\"segment\"] = temp_df.channel2_segment\n",
    "    temp_df[\"method\"] = temp_df.channel2_laterality\n",
    "\n",
    "    idx = temp_df.channel1_segment.isna()\n",
    "    temp_df = temp_df[idx].copy()\n",
    "    temp_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    temp_mat = temp_mat[idx, :, :]\n",
    "\n",
    "    if df is None:\n",
    "        df = temp_df.copy()\n",
    "        mat = temp_mat\n",
    "    else:\n",
    "        df = pd.concat([df, temp_df], ignore_index=True).copy()\n",
    "        mat = np.vstack((mat, temp_mat))\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df, encoder_dict = data.build(df)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot(df, encoder_dict=encoder_dict, mat=mat[:, :, 0], time=time);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpyro.distributions.mixtures import MixtureGeneral\n",
    "\n",
    "\n",
    "class MixtureModel(Baseline):\n",
    "    def __init__(self, config: HBMepConfig):\n",
    "        super(MixtureModel, self).__init__(config=config)\n",
    "        self.name = \"Mixture_Model\"\n",
    "\n",
    "        self.columns = [PARTICIPANT] + FEATURES\n",
    "        self.x = np.linspace(0, 450, 1000)\n",
    "\n",
    "    def _model(self, intensity, participant, feature0, feature1, response_obs=None):\n",
    "        n_data = intensity.shape[0]\n",
    "        n_participant = np.unique(participant).shape[0]\n",
    "        n_feature0 = np.unique(feature0).shape[0]\n",
    "        n_feature1 = np.unique(feature1).shape[0]\n",
    "\n",
    "        with numpyro.plate(\"n_participant\", n_participant, dim=-1):\n",
    "            # Hyperriors\n",
    "            a_mean = numpyro.sample(\n",
    "                site.a_mean,\n",
    "                dist.TruncatedDistribution(dist.Normal(150, 50), low=0)\n",
    "            )\n",
    "            a_scale = numpyro.sample(site.a_scale, dist.HalfNormal(20))\n",
    "\n",
    "            b_scale = numpyro.sample(site.b_scale, dist.HalfNormal(0.1))\n",
    "\n",
    "            h_scale = numpyro.sample(\"h_scale\", dist.HalfNormal(10))\n",
    "            v_scale = numpyro.sample(\"v_scale\", dist.HalfNormal(10))\n",
    "\n",
    "            lo_scale = numpyro.sample(site.lo_scale, dist.HalfNormal(0.2))\n",
    "\n",
    "            noise_offset_scale = numpyro.sample(\n",
    "                site.noise_offset_scale,\n",
    "                dist.HalfCauchy(0.2)\n",
    "            )\n",
    "            noise_slope_scale = numpyro.sample(\n",
    "                site.noise_slope_scale,\n",
    "                dist.HalfCauchy(0.2)\n",
    "            )\n",
    "\n",
    "            noise_mixture_scale = numpyro.sample(\n",
    "                \"noise_mixture_scale\",\n",
    "                dist.HalfCauchy(0.2)\n",
    "            )\n",
    "\n",
    "            with numpyro.plate(\"n_feature0\", n_feature0, dim=-2):\n",
    "                with numpyro.plate(\"n_feature1\", n_feature1, dim=-3):\n",
    "                    # Priors\n",
    "                    a = numpyro.sample(\n",
    "                        site.a,\n",
    "                        dist.TruncatedDistribution(dist.Normal(a_mean, a_scale), low=0)\n",
    "                    )\n",
    "                    b = numpyro.sample(site.b, dist.HalfNormal(b_scale))\n",
    "\n",
    "                    h = numpyro.sample(\"h\", dist.HalfNormal(h_scale))\n",
    "                    v = numpyro.sample(\"v\", dist.HalfNormal(v_scale))\n",
    "\n",
    "                    lo = numpyro.sample(site.lo, dist.HalfNormal(lo_scale))\n",
    "\n",
    "                    noise_offset = numpyro.sample(\n",
    "                        site.noise_offset,\n",
    "                        dist.HalfCauchy(noise_offset_scale)\n",
    "                    )\n",
    "                    noise_slope = numpyro.sample(\n",
    "                        site.noise_slope,\n",
    "                        dist.HalfCauchy(noise_slope_scale)\n",
    "                    )\n",
    "\n",
    "                    noise_mixture = numpyro.sample(\n",
    "                        \"noise_mixture\",\n",
    "                        dist.HalfCauchy(noise_mixture_scale)\n",
    "                    )\n",
    "\n",
    "        \"\"\" Model \"\"\"\n",
    "        mean = numpyro.deterministic(\n",
    "            site.mean,\n",
    "            lo[feature1, feature0, participant] + \\\n",
    "            jnp.maximum(\n",
    "                0,\n",
    "                -1 + \\\n",
    "                (h[feature1, feature0, participant] + 1) / \\\n",
    "                jnp.power(\n",
    "                    1 + \\\n",
    "                    (jnp.power(1 + h[feature1, feature0, participant], v[feature1, feature0, participant]) - 1) * \\\n",
    "                    jnp.exp(-b[feature1, feature0, participant] * (intensity - a[feature1, feature0, participant])),\n",
    "                    1 / v[feature1, feature0, participant]\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "        sigma = numpyro.deterministic(\n",
    "            \"sigma\",\n",
    "            noise_offset[feature1, feature0, participant] + \\\n",
    "            noise_slope[feature1, feature0, participant] * \\\n",
    "            mean\n",
    "        )\n",
    "\n",
    "        mixing_distribution = dist.Categorical(probs=jnp.array([.9, .1]))\n",
    "\n",
    "        component_distributions = [\n",
    "            dist.TruncatedNormal(mean, sigma, low=0),\n",
    "            dist.TruncatedNormal(\n",
    "                mean,\n",
    "                noise_mixture[feature1, feature0, participant],\n",
    "                low=0\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        Mixture = MixtureGeneral(\n",
    "            mixing_distribution=mixing_distribution,\n",
    "            component_distributions=component_distributions\n",
    "        )\n",
    "\n",
    "        with numpyro.plate(\"data\", n_data):\n",
    "            # return numpyro.sample(\"obs\", dist.TruncatedNormal(mean, sigma, low=0), obs=response_obs)\n",
    "            return numpyro.sample(\"obs\", Mixture, obs=response_obs)\n",
    "\n",
    "    @timing\n",
    "    def run_inference(self, df: pd.DataFrame) -> tuple[numpyro.infer.mcmc.MCMC, dict]:\n",
    "        \"\"\"\n",
    "        Run MCMC inference\n",
    "        \"\"\"\n",
    "        response = df[RESPONSE].to_numpy().reshape(-1,)\n",
    "        participant = df[PARTICIPANT].to_numpy().reshape(-1,)\n",
    "        feature0 = df[FEATURES[0]].to_numpy().reshape(-1,)\n",
    "        feature1 = df[FEATURES[1]].to_numpy().reshape(-1,)\n",
    "        intensity = df[INTENSITY].to_numpy().reshape(-1,)\n",
    "\n",
    "        # MCMC\n",
    "        nuts_kernel = NUTS(self._model)\n",
    "        mcmc = MCMC(nuts_kernel, **self.config.MCMC_PARAMS)\n",
    "        rng_key = jax.random.PRNGKey(self.random_state)\n",
    "        # logger.info(f\"Running inference with {self.name} ...\")\n",
    "        mcmc.run(rng_key, intensity, participant, feature0, feature1, response)\n",
    "        posterior_samples = mcmc.get_samples()\n",
    "\n",
    "        return mcmc, posterior_samples\n",
    "\n",
    "    def _get_estimates(\n",
    "        self,\n",
    "        posterior_samples: dict,\n",
    "        posterior_means: dict,\n",
    "        c: tuple\n",
    "    ):\n",
    "        a = posterior_means[site.a][c[::-1]]\n",
    "        b = posterior_means[site.b][c[::-1]]\n",
    "        h = posterior_means[\"h\"][c[::-1]]\n",
    "        v = posterior_means[\"v\"][c[::-1]]\n",
    "        lo = posterior_means[site.lo][c[::-1]]\n",
    "\n",
    "        y = lo + jnp.maximum(\n",
    "            0,\n",
    "            -1 + (h + 1) / \\\n",
    "            jnp.power(1 + (jnp.power(1 + h, v) - 1) * jnp.exp(-b * (self.x - a)), 1 / v)\n",
    "        )\n",
    "\n",
    "        threshold_samples = posterior_samples[site.a][:, c[2], c[1], c[0]]\n",
    "        hpdi_interval = hpdi(threshold_samples, prob=0.95)\n",
    "\n",
    "        return y, threshold_samples, hpdi_interval\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MixtureModel(config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run MCMC inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-26 15:10:15,229 - jax._src.xla_bridge - INFO - Unable to initialize backend 'tpu_driver': NOT_FOUND: Unable to find driver in registry given worker: \n",
      "2023-05-26 15:10:15,230 - jax._src.xla_bridge - INFO - Unable to initialize backend 'cuda': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'\n",
      "2023-05-26 15:10:15,230 - jax._src.xla_bridge - INFO - Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'\n",
      "2023-05-26 15:10:15,231 - jax._src.xla_bridge - INFO - Unable to initialize backend 'tpu': INVALID_ARGUMENT: TpuPlatform is not available.\n",
      "2023-05-26 15:10:15,231 - jax._src.xla_bridge - INFO - Unable to initialize backend 'plugin': xla_extension has no attributes named get_plugin_device_client. Compile TensorFlow with //tensorflow/compiler/xla/python:enable_plugin_device set to true (defaults to false) to enable this.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c39418038104c82824c4dcbd532ab99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1999feefff7f4bb6a9a96c06c5f3c2ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ee7500935d44b1e90f0dbecc595c2f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc8e2c49f3de4783b44cab67860636d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-26 15:26:40,607 - hb_mep.utils.utils - INFO - func:run_inference took: 16 min and 25.38 sec\n"
     ]
    }
   ],
   "source": [
    "mcmc, posterior_samples = model.run_inference(df=df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                            mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "              a[0,0,0]     45.47      1.28     45.65     43.48     47.46    209.95      1.01\n",
      "              a[0,1,0]    121.31      1.75    121.51    118.93    124.02     25.13      1.20\n",
      "              a[0,2,0]    227.04      2.10    227.48    223.93    229.92    185.35      1.01\n",
      "              a[0,3,0]    220.25      6.61    217.42    212.52    233.26      2.64      2.43\n",
      "              a[1,0,0]    202.80      5.84    201.07    196.35    216.23     33.00      1.12\n",
      "              a[1,1,0]    174.78     52.04    174.87     88.67    256.02     54.91      1.10\n",
      "              a[1,2,0]    200.71      6.93    202.88    188.24    208.37     73.99      1.06\n",
      "              a[1,3,0]    209.21      8.90    208.88    196.41    223.73      4.57      1.41\n",
      "             a_mean[0]    173.07     17.51    173.98    146.94    202.08    142.80      1.02\n",
      "            a_scale[0]     52.13      8.87     51.60     37.74     65.92     73.57      1.06\n",
      "              b[0,0,0]      0.04      0.03      0.03      0.01      0.07     45.94      1.11\n",
      "              b[0,1,0]      0.02      0.01      0.02      0.01      0.03     20.58      1.15\n",
      "              b[0,2,0]      0.04      0.04      0.03      0.01      0.08     42.70      1.11\n",
      "              b[0,3,0]      0.02      0.01      0.01      0.00      0.03     32.78      1.12\n",
      "              b[1,0,0]      0.03      0.03      0.02      0.00      0.06     32.17      1.12\n",
      "              b[1,1,0]      0.03      0.03      0.02      0.00      0.06    105.76      1.07\n",
      "              b[1,2,0]      0.02      0.02      0.01      0.00      0.04     35.83      1.13\n",
      "              b[1,3,0]      0.02      0.01      0.01      0.00      0.03     27.53      1.15\n",
      "            b_scale[0]      0.03      0.03      0.03      0.01      0.07     33.56      1.14\n",
      "              h[0,0,0]      3.99      0.28      3.98      3.56      4.41     48.06      1.07\n",
      "              h[0,1,0]      3.03      0.45      2.98      2.38      3.62      5.29      1.33\n",
      "              h[0,2,0]      3.71      3.07      2.63      1.40      6.90    127.14      1.03\n",
      "              h[0,3,0]      4.41      6.28      1.65      0.13     11.97      6.21      1.54\n",
      "              h[1,0,0]      6.51      5.02      5.22      1.10     11.94     26.27      1.12\n",
      "              h[1,1,0]      5.37      5.36      3.88      0.00     12.29      9.10      1.21\n",
      "              h[1,2,0]      4.48      4.22      3.06      0.29     10.01     33.58      1.15\n",
      "              h[1,3,0]      5.41      4.88      3.96      0.32     11.62     31.83      1.14\n",
      "            h_scale[0]      6.25      3.49      5.39      1.95     11.10      9.13      1.33\n",
      "             lo[0,0,0]      0.03      0.00      0.03      0.03      0.04    296.58      1.01\n",
      "             lo[0,1,0]      0.02      0.00      0.02      0.02      0.02    250.33      1.01\n",
      "             lo[0,2,0]      0.02      0.00      0.02      0.02      0.02     55.47      1.05\n",
      "             lo[0,3,0]      0.02      0.00      0.02      0.02      0.02      4.55      1.46\n",
      "             lo[1,0,0]      0.03      0.00      0.03      0.02      0.03    207.81      1.02\n",
      "             lo[1,1,0]      0.02      0.02      0.01      0.00      0.05     21.75      1.09\n",
      "             lo[1,2,0]      0.02      0.00      0.02      0.02      0.03     60.73      1.06\n",
      "             lo[1,3,0]      0.02      0.00      0.02      0.02      0.03      9.77      1.20\n",
      "           lo_scale[0]      0.03      0.01      0.03      0.02      0.04    142.82      1.05\n",
      "  noise_mixture[0,0,0]      1.35      1.28      1.19      0.00      2.81    150.02      1.03\n",
      "  noise_mixture[0,1,0]      0.31      0.27      0.28      0.00      0.62      4.64      1.36\n",
      "  noise_mixture[0,2,0]      0.07      0.41      0.00      0.00      0.00     48.59      1.06\n",
      "  noise_mixture[0,3,0]      0.72      0.42      0.78      0.04      1.10      3.38      1.68\n",
      "  noise_mixture[1,0,0]      0.95      0.37      0.88      0.45      1.42    109.73      1.04\n",
      "  noise_mixture[1,1,0]      2.83     53.56      0.27      0.00      2.69   1725.26      1.00\n",
      "  noise_mixture[1,2,0]      0.50      0.31      0.44      0.23      0.76    180.52      1.04\n",
      "  noise_mixture[1,3,0]      0.18      0.15      0.17      0.00      0.34      4.38      1.37\n",
      "noise_mixture_scale[0]      0.36      0.29      0.30      0.02      0.68     11.57      1.15\n",
      "   noise_offset[0,0,0]      0.00      0.00      0.00      0.00      0.00     81.77      1.06\n",
      "   noise_offset[0,1,0]      0.01      0.02      0.00      0.00      0.04      2.10      5.40\n",
      "   noise_offset[0,2,0]      0.00      0.00      0.00      0.00      0.00     52.10      1.13\n",
      "   noise_offset[0,3,0]      0.00      0.00      0.00      0.00      0.00     29.48      1.11\n",
      "   noise_offset[1,0,0]      0.00      0.00      0.00      0.00      0.00     16.45      1.17\n",
      "   noise_offset[1,1,0]      0.00      0.02      0.00      0.00      0.00   1372.13      1.00\n",
      "   noise_offset[1,2,0]      0.00      0.00      0.00      0.00      0.00    152.77      1.02\n",
      "   noise_offset[1,3,0]      0.00      0.00      0.00      0.00      0.00     42.99      1.05\n",
      " noise_offset_scale[0]      0.00      0.00      0.00      0.00      0.00     19.51      1.15\n",
      "    noise_slope[0,0,0]      0.24      0.05      0.24      0.17      0.32     83.21      1.05\n",
      "    noise_slope[0,1,0]      0.28      0.06      0.27      0.19      0.38      3.99      1.50\n",
      "    noise_slope[0,2,0]      0.44      0.09      0.43      0.30      0.57     47.59      1.03\n",
      "    noise_slope[0,3,0]      0.22      0.18      0.11      0.07      0.53      2.28      3.45\n",
      "    noise_slope[1,0,0]      0.28      0.05      0.27      0.19      0.37     66.36      1.01\n",
      "    noise_slope[1,1,0]      0.98      4.43      0.28      0.00      1.69    781.63      1.01\n",
      "    noise_slope[1,2,0]      0.37      0.08      0.36      0.24      0.48    152.97      1.05\n",
      "    noise_slope[1,3,0]      0.40      0.20      0.32      0.16      0.71      2.63      2.30\n",
      "  noise_slope_scale[0]      0.29      0.12      0.28      0.11      0.47     45.25      1.09\n",
      "              v[0,0,0]      2.02      2.34      1.36      0.01      4.31     43.01      1.11\n",
      "              v[0,1,0]      0.59      0.62      0.37      0.00      1.57     29.70      1.13\n",
      "              v[0,2,0]      2.89      2.96      1.99      0.03      6.46     52.24      1.10\n",
      "              v[0,3,0]      4.51      6.40      2.14      0.00     11.74     32.24      1.16\n",
      "              v[1,0,0]      5.11      4.59      3.87      0.00     11.00     29.53      1.13\n",
      "              v[1,1,0]      4.30      6.04      2.09      0.00     10.85     42.03      1.09\n",
      "              v[1,2,0]      5.35      6.57      3.11      0.00     12.86     40.31      1.13\n",
      "              v[1,3,0]      6.29      6.15      4.58      0.01     14.01     43.07      1.14\n",
      "            v_scale[0]      5.41      4.53      4.01      0.11     11.50     22.75      1.19\n",
      "\n",
      "Number of divergences: 33\n"
     ]
    }
   ],
   "source": [
    "mcmc.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot(df=df, posterior_samples=posterior_samples);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "69fe5a65376e3e8c837f422745dfbf05401d1d09350c8bf56abec85cd76c8bea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
